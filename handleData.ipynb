{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(csv_file, pickle_file):\n",
    "  \"\"\"\n",
    "  Loads a CSV file, cleans and preprocesses the data, and stores it in a pickle file.\n",
    "  Args:\n",
    "      csv_file (str): Path to the CSV file containing job data.\n",
    "      pickle_file (str): Path to the pickle file where preprocessed data will be stored.\n",
    "  Returns:\n",
    "      pandas.DataFrame: The preprocessed DataFrame containing job data.\n",
    "  \"\"\"\n",
    "\n",
    "  df = pd.read_csv(csv_file)\n",
    "  df = df.dropna()  # Remove rows with missing values (optional)\n",
    "  tdif = TfidfVectorizer(stop_words='english')\n",
    "  df['jobdescription'] = df['jobdescription'].fillna('')\n",
    "  tdif_matrix = tdif.fit_transform(df['jobdescription'])\n",
    "\n",
    "  with open(pickle_file, 'wb') as f:\n",
    "      data = {'df': df, 'tdif': tdif, 'tdif_matrix': tdif_matrix}\n",
    "      pickle.dump(data, f)\n",
    "\n",
    "  return df, tdif, tdif_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from pickle file\n"
     ]
    }
   ],
   "source": [
    "csv_file = './saved_job_data_2.csv'\n",
    "pickle_file = 'preprocessed_data.pkl'\n",
    "\n",
    "try:\n",
    "  with open(pickle_file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    df = data['df']\n",
    "    tdif = data['tdif']  # Load TF-IDF vectorizer if needed\n",
    "    tdif_matrix = data['tdif_matrix']  # Load TF-IDF matrix if needed\n",
    "    print(\"Loaded data from pickle file\")\n",
    "except FileNotFoundError:\n",
    "  print(\"Pickle file not found, loading and preprocessing data from CSV...\")\n",
    "  df, tdif, tdif_matrix = load_and_preprocess_data(csv_file, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3417, 34095)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdif_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>company</th>\n",
       "      <th>jobdescription</th>\n",
       "      <th>joblocation_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOMATION TEST ENGINEER</td>\n",
       "      <td>Digital Intelligence Systems, LLC</td>\n",
       "      <td>Looking for Selenium engineers...must have sol...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Information Security Engineer</td>\n",
       "      <td>University of Chicago/IT Services</td>\n",
       "      <td>The University of Chicago has a rapidly growin...</td>\n",
       "      <td>Chicago, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Solutions Architect</td>\n",
       "      <td>Galaxy Systems, Inc.</td>\n",
       "      <td>GalaxE.SolutionsEvery day, our solutions affec...</td>\n",
       "      <td>Schaumburg, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Java Developer (mid level)- FT- GREAT culture,...</td>\n",
       "      <td>TransTech LLC</td>\n",
       "      <td>Java DeveloperFull-time/direct-hireBolingbrook...</td>\n",
       "      <td>Bolingbrook, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Matrix Resources</td>\n",
       "      <td>Midtown based high tech firm has an immediate ...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            jobtitle  \\\n",
       "0                           AUTOMATION TEST ENGINEER   \n",
       "1                      Information Security Engineer   \n",
       "2                       Business Solutions Architect   \n",
       "3  Java Developer (mid level)- FT- GREAT culture,...   \n",
       "4                                    DevOps Engineer   \n",
       "\n",
       "                             company  \\\n",
       "0  Digital Intelligence Systems, LLC   \n",
       "1  University of Chicago/IT Services   \n",
       "2               Galaxy Systems, Inc.   \n",
       "3                      TransTech LLC   \n",
       "4                   Matrix Resources   \n",
       "\n",
       "                                      jobdescription joblocation_address  \n",
       "0  Looking for Selenium engineers...must have sol...         Atlanta, GA  \n",
       "1  The University of Chicago has a rapidly growin...         Chicago, IL  \n",
       "2  GalaxE.SolutionsEvery day, our solutions affec...      Schaumburg, IL  \n",
       "3  Java DeveloperFull-time/direct-hireBolingbrook...     Bolingbrook, IL  \n",
       "4  Midtown based high tech firm has an immediate ...         Atlanta, GA  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert to database . job table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jobtitle, company, jobdescription, joblocation_address'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_columns = \", \".join(df.columns.tolist())\n",
    "table_columns   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INSERT INTO job (jobtitle, company, jobdescription, joblocation_address) VALUES (%s, %s, %s, ..., %s)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_insert = f\"\"\"INSERT INTO job ({table_columns}) VALUES (%s, %s, %s, ..., %s)\"\"\"\n",
    "sql_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21947 entries, 0 to 21999\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   jobtitle             21947 non-null  object\n",
      " 1   company              21947 non-null  object\n",
      " 2   jobdescription       21947 non-null  object\n",
      " 3   joblocation_address  21947 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 857.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company name at row 1: Digital Intelligence Systems, LLC\n"
     ]
    }
   ],
   "source": [
    "# Accessing data using label (assuming \"company\" is the column name)\n",
    "# company_name = df.loc[0, \"company\"]\n",
    "\n",
    "# Accessing data using integer position (assuming \"company\" is at index 1)\n",
    "company_name = df.iloc[0, 1]  # This would work if \"company\" is the second column\n",
    "\n",
    "print(f\"Company name at row 1: {company_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dung tdif matrix và linear kernel để tính ma trận độ tương đồng cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3417, 34095)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdif_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tính toán ma trận độ tương đồng cosine giữa tất cả các mô tả công việc. Độ tương đồng cosine đo lường mức độ giống nhau của hai tài liệu dựa trên vectơ TF-IDF của chúng.\n",
    "cosine_sim=linear_kernel(tdif_matrix,tdif_matrix)\n",
    "type(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tạo một Series ánh xạ các tiêu đề công việc duy nhất với các chỉ mục tương ứng của chúng trong DataFrame (để truy xuất hiệu quả).\n",
    "indices=pd.Series(df.index, index=df['jobtitle']).drop_duplicates()\n",
    "type(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation(title, cosine_sim=cosine_sim):\n",
    "    try:\n",
    "        # Get the index of the input title\n",
    "        idx = indices[title]\n",
    "\n",
    "        # Calculate cosine similarity scores for all jobs\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))  # Enumerate indices and similarity scores\n",
    "\n",
    "        # Handle potential empty similarity scores (e.g., no related jobs)\n",
    "        if not sim_scores:\n",
    "            print(f\"No similar jobs found for '{title}'.\")\n",
    "            return []\n",
    "\n",
    "        # Sort jobs by similarity score in descending order (most similar first)\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Select the top 15 jobs (excluding the input job at index 0)\n",
    "        top_15_indices = [i for i, _ in sim_scores[:16]]  # Get top 15 indices (16 to exclude the input)\n",
    "\n",
    "        # Extract job titles from the DataFrame using the selected indices\n",
    "        recommendations = df['jobtitle'].iloc[top_15_indices[1:]]  # Exclude input job at index 0\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"Job title '{title}' not found in the data.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2900                                 IT Security Engineer\n",
       "1334                     Multiple Cyber Security Openings\n",
       "773                         Application Security Engineer\n",
       "1055                                  IT Security Manager\n",
       "2134                                   Security Architect\n",
       "202                             Senior Security Architect\n",
       "2132                                  IT Security Analyst\n",
       "2096                                   Security Architect\n",
       "217     Information Security Manager - IT Security, CI...\n",
       "1649                             Senior Security Engineer\n",
       "968             Security Analyst / Security Administrator\n",
       "2661                     Sr Information Security Engineer\n",
       "1614                  Sr. Infrastructure Security Analyst\n",
       "1678                                   AVP Cyber Security\n",
       "923                                IT Security Consultant\n",
       "Name: jobtitle, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendation('Lead DevOps Engineer',cosine_sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function insert to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mysql-connector-python in c:\\users\\win-pro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (8.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection.MySQLConnection object at 0x000002E23AB0E5A0>\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"\"\n",
    ")\n",
    "\n",
    "print(mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Get the table columns (assuming you know the column names)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m table_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())  \u001b[38;5;66;03m# Convert list to comma-separated string\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     connection \u001b[38;5;241m=\u001b[39m mysql\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdb_config)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Get the table columns (assuming you know the column names)\n",
    "table_columns = \", \".join(df.columns.tolist())  # Convert list to comma-separated string\n",
    "\n",
    "try:\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    # Prepare SQL statement with placeholders for data\n",
    "    sql_insert = f\"\"\"INSERT INTO your_table_name ({table_columns}) VALUES (%s, %s, %s, ..., %s)\"\"\"\n",
    "    values = df.to_records(index=False).tolist()  # Convert DataFrame to list of tuples\n",
    "\n",
    "    cursor.executemany(sql_insert, values)\n",
    "    connection.commit()\n",
    "\n",
    "    print(f\"Successfully inserted {cursor.rowcount} rows to the database.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Error connecting to database:\", err)\n",
    "finally:\n",
    "    if connection:\n",
    "        connection.close()\n",
    "        cursor.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
